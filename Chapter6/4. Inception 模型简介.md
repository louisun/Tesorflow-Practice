# 4. Inception 模型简介

inception 是创立之初、开端的意思

Inception-v3 模型中的 Inception 结构是将不同卷积层通过**并联**，而非*串联*的方式结合在一起。



![](https://ws1.sinaimg.cn/large/006tNbRwgy1fw0l8xknm9j30v20l4ayd.jpg)

Inception 模块先用不同尺寸的 filter 处理输入矩阵，虽然过滤器大小不同，但如果都用全 0 填充且步长为 1，那么前向传播得到的矩阵长和宽都和输入矩阵一致。这样经过不同过滤器处理的结果矩阵可以拼接成一个更深的输出矩阵：长和宽与输入一样，深度为红蓝黄三个输出矩阵深度之和。

这只是 Inception 模块的核心思想，真正的 Inception-v3 模型使用的 Inception 模块更加复杂多样。


![](https://ws4.sinaimg.cn/large/006tNbRwgy1fw0ljgx61wj30hs06n3ys.jpg)

Inception3-v3 有46层，11个 Inception 模块，96 个卷积层，每个卷积层都要写多行代码，这样代码可读性很差，为了更方便实现这类复杂的神经网络，可以使用 `Tensorflow-Slim` 工具来**更简单地**实现一个卷积层.

```python
# 直接使用 Tensorflow 原始 api 
with tf.variable_scope(scope_name):
    weights = tf.get_variable("weight", ...)
    bias = tf.get_variable("bias", ...)
    conv = tf.nn.conv2d(...)
    relu = tf.nn.relu(tf.nn.bias_add(conv, biases))


# 改用 Tensorflow-Slim 实现卷积层，一行即可实现一个卷积层前向传播
# slim.conv2d 有3个参数必填，第一个为输入节点矩阵，第二个当前卷积层过滤器深度，第三个是过滤器尺寸，可选的参数有过滤器移动步数、是否全0填充，激活函数选择、变量命名空间等
net = slim.conv2d(input, 32, [3,3])
```


